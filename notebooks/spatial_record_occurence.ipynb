#!/usr/bin/env python
# coding: utf-8

# ## Code to download and process CMIP6 data

# In[ ]:





# Modified from the "first way" in Ryan Abernathey's "CMIP6 in the Cloud Five Ways", see:
# https://medium.com/pangeo/cmip6-in-the-cloud-five-ways-96b177abe396

# In[90]:


from matplotlib import pyplot as plt
import numpy as np
import xarray as xr

#get_ipython().run_line_magic('matplotlib', 'inline')


# In[91]:


#!/usr/bin/env python
from __future__ import print_function
import requests
import xml.etree.ElementTree as ET

# Author: Unknown
# I got the original version from a word document published by ESGF
# https://docs.google.com/document/d/1pxz1Kd3JHfFp8vR2JCVBfApbsHmbUQQstifhGNdc6U0/edit?usp=sharing

# API AT: https://github.com/ESGF/esgf.github.io/wiki/ESGF_Search_REST_API#results-pagination

def esgf_search(server="https://esgf-node.llnl.gov/esg-search/search",
                files_type="OPENDAP", local_node=True, project="CMIP6",
                verbose=False, format="application%2Fsolr%2Bjson",
                use_csrf=False, **search):
    client = requests.session()
    payload = search
    payload["project"] = project
    payload["type"]= "File"
    if local_node:
        payload["distrib"] = "false"
    if use_csrf:
        client.get(server)
        if 'csrftoken' in client.cookies:
            # Django 1.6 and up
            csrftoken = client.cookies['csrftoken']
        else:
            # older versions
            csrftoken = client.cookies['csrf']
        payload["csrfmiddlewaretoken"] = csrftoken

    payload["format"] = format

    offset = 0
    numFound = 10000
    all_files = []
    files_type = files_type.upper()
    while offset < numFound:
        payload["offset"] = offset
        url_keys = [] 
        for k in payload:
            url_keys += ["{}={}".format(k, payload[k])]

        url = "{}/?{}".format(server, "&".join(url_keys))
        print(url)
        r = client.get(url)
        r.raise_for_status()
        resp = r.json()["response"]
        numFound = int(resp["numFound"])
        resp = resp["docs"]
        offset += len(resp)
        for d in resp:
            if verbose:
                for k in d:
                    print("{}: {}".format(k,d[k]))
            url = d["url"]
            for f in d["url"]:
                sp = f.split("|")
                if sp[-1] == files_type:
                    all_files.append(sp[0].split(".html")[0])
    return sorted(all_files)


# In[92]:


#models which claim to have run these experiments:
models = ["ACCESS-CM2", "ACCESS-ESM1-5", "AWI-CM-1-1-MR", "CAMS-CSM1-0", "CMCC-CM2-SR5", "CMCC-ESM2",          
          "CNRM-CM6-1","CNRM-CM6-1-HR", "CNRM-ESM2-1", "EC-Earth3", "EC-Earth3-CC",
          "EC-Earth3-Veg", "EC-Earth3-Veg-LR", "GFDL-CM4",  "GFDL-ESM4", "HadGEM3-GC31-LL",
         "IITM-ESM", "INM-CM4-8", "INM-CM5-0", "IPSL-CM6A-LR",
          "NorESM2-LM", "NorESM2-MM", "TaiESM1", 
          "UKESM1-0-LL", "UKESM1-1-LL"]
m = len(models)

lim = [2, 2, 86, 1, 4, 4, 1, 2, 1, 86, 86, 86, 86, 5, 5,  2, 17, 2, 2, 1, 9, 9, 9, 2, 2 ]

issues = ["CAMS-CSM1-0","CNRM-CM6-1","CNRM-ESM2-1","GFDL-CM4"]


# In[5]:


#Loop through models and calculate global-mean temperature and maximum daily-mean temperatures
#To calculate daily-maximum temperatures change variable_id="tas" to variable_id="tasmax"

for i in range(15,16):
    print("doing", models[i])
    result = esgf_search(activity_id='ScenarioMIP', table_id='day', variable_id='tas', 
                                 experiment_id = 'ssp245', source_id = models[i])
    
    if lim[i] == 1:
        files_to_open = result[:]
        ds = xr.open_dataset(files_to_open[0])
    elif i == 13 or i == 19:
        files_to_open = result[:lim[i]]
        ds = xr.open_mfdataset(files_to_open, chunks={'time': '100MB'}, decode_times=False)
    else:
        files_to_open = result[:lim[i]]
        ds = xr.open_mfdataset(files_to_open)
    print("loaded data, get annual maxima")
    print(files_to_open)
    lat = ds.lat[:]
    lon = ds.lon[:]
    
    rad_lat = lat * np.pi / 180.
    rad_lon = lon * np.pi / 180.
    cos_lat = np.cos(rad_lat)
    
  #  if i == 15:
  #      l = 86
  #  else:
    l = 85
    
    max_temps = np.zeros(l) #array to store data
    mean_temps = np.zeros(l) #array to store data
    
    #array to store data (new)
    #max_temps_2 = np.zeros(l)
    max_lon = np.zeros(l)
    max_lat = np.zeros(l)

    for j in range(l):
        if j % 10 == 0:
            print(j)
        max_temps[j] = np.max(ds.tas[j * 365:(j + 1) * 365])
        
        #temporary variable to store array of the max temps for a given year
        t2=np.array(ds.tas[j * 365:(j + 1) * 365])
        
        #finding index of maximum temp for that year, puts it back into the original form of the arrray (to show temp,Lat,and Lon)
        ind=np.unravel_index(np.argmax(t2, axis=None),t2.shape)
        
        #set up array for each max temp data point (temp, Lat, Lon)
        #max_temps_2[j]=np.array(t2[ind])
        max_lat[j]=np.array(ds.lat[ind[1]])
        max_lon[j]=np.array(ds.lon[ind[2]])

        
    np.save("data/" + models[i] + "_max_daily_lon", max_lon)
    np.save("data/" + models[i] + "_max_daily_lat", max_lat)
        
    #########################################
        
    # temp = np.mean(ds.tas[j * 365:(j + 1) * 365], axis = 0)
    # mean_temps[j] = np.trapz(np.trapz(temp * cos_lat, rad_lon, axis = 1), rad_lat) / 4. / np.pi

    
    #Save's
    #np.save("data/" + models[i] + "_max_daily_temp", max_temps)
    #np.save("data/" + models[i] + "_mean_temp", mean_temps)





#%%
#models which claim to have run these experiments:
models = ["ACCESS-CM2", "ACCESS-ESM1-5", "AWI-CM-1-1-MR", "CAMS-CSM1-0", "CMCC-CM2-SR5", "CMCC-ESM2",          
          "CNRM-CM6-1","CNRM-CM6-1-HR", "CNRM-ESM2-1", "EC-Earth3", "EC-Earth3-CC",
          "EC-Earth3-Veg", "EC-Earth3-Veg-LR", "GFDL-CM4",  "GFDL-ESM4", "HadGEM3-GC31-LL",
         "IITM-ESM", "INM-CM4-8", "INM-CM5-0", "IPSL-CM6A-LR",
          "NorESM2-LM", "NorESM2-MM", "TaiESM1", 
          "UKESM1-0-LL"]
m = len(models)

lim = [2, 2, 86, 1, 4, 4, 1, 2, 1, 86, 86, 86, 86, 5, 5,  2, 17, 2, 2, 1, 9, 9, 9, 2, 2 ]

issues = ["CAMS-CSM1-0","CNRM-CM6-1","CNRM-ESM2-1","GFDL-CM4"]

import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import numpy as np


m = len(models)
l = 85  # Length of the dataset for each model

# Initialize arrays for latitudes and longitudes
lats = np.zeros((m, l))
lons = np.zeros((m, l))

# Load data for each model
for i in range(m):
    lats[i] = np.load("/Applications/max_lat_lon/Data Files and Notebooks/" + models[i] + "_max_daily_lat.npy")[:85]
    lons[i] = np.load("/Applications/max_lat_lon/Data Files and Notebooks/" + models[i] + "_max_daily_lon.npy")[:85]

# Your color map
cmap = plt.cm.viridis

# Calculate the number of rows and columns for the subplot grid
# Set the number of columns per row (e.g., 4 or 6 columns seem reasonable)
columns_per_row = 6
num_rows = m // columns_per_row + (m % columns_per_row > 0)

# Define your figure size dynamically based on the number of rows and columns
fig_width = columns_per_row * 5  # increased width for better fit
fig_height = num_rows * 3.5  # increased height for individual subplot clarity

fig = plt.figure(figsize=(fig_width, fig_height))

# Define years based on the provided dataset length 'l' for each model
years = np.linspace(2015, 2100, l)  # Adjust 'l' if different years have different lengths

for i in range(m):
    # Convert flat index i to row/column index
    row_idx = i // columns_per_row
    col_idx = i % columns_per_row
    
    # Create subplot at correct location - note that add_subplot indices start at 1
    ax = fig.add_subplot(num_rows, columns_per_row, i+1, projection=ccrs.PlateCarree())
    scatter = ax.scatter(lons[i], lats[i], s=20, c=years, cmap=cmap, vmin=2015, vmax=2100)
    ax.coastlines()
    ax.add_feature(cfeature.BORDERS)
    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())
    ax.set_title(models[i], fontsize=10)  # Adjust fontsize if necessary

# Make room for colorbar
plt.subplots_adjust(right=0.85)  # Leave space on the right side of the subplots

# Add colorbar
cbar_ax = fig.add_axes([0.87, 0.15, 0.02, 0.7])  # Position colorbar axes
cbar = fig.colorbar(scatter, cax=cbar_ax)
cbar.set_label('Year')
cbar.set_ticks(np.linspace(2015, 2100, 18))  # Set to have a tick every 5 years
cbar.set_ticklabels(np.arange(2015, 2101, 5).astype(int))  # Show every 5 years

plt.show()


#%%

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cfeature

# Define models and load data
models = ["ACCESS-CM2", "ACCESS-ESM1-5", "AWI-CM-1-1-MR", "CAMS-CSM1-0", "CMCC-CM2-SR5", "CMCC-ESM2",
          "CNRM-CM6-1", "CNRM-CM6-1-HR", "CNRM-ESM2-1", "EC-Earth3", "EC-Earth3-CC",
          "EC-Earth3-Veg", "EC-Earth3-Veg-LR", "GFDL-CM4", "GFDL-ESM4", "HadGEM3-GC31-LL",
          "IITM-ESM", "INM-CM4-8", "INM-CM5-0", "IPSL-CM6A-LR",
          "NorESM2-LM", "NorESM2-MM", "TaiESM1", "UKESM1-0-LL"]
m = len(models)
l = 85  # Length of the dataset for each model

# Initialize arrays for latitudes and longitudes
lats = np.zeros((m, l))
lons = np.zeros((m, l))

# Load data for each model
for i in range(m):
    lats[i] = np.load("/Applications/max_lat_lon/Data Files and Notebooks/" + models[i] + "_max_daily_lat.npy")[:85]
    lons[i] = np.load("/Applications/max_lat_lon/Data Files and Notebooks/" + models[i] + "_max_daily_lon.npy")[:85]

# Define years for each model
years = np.linspace(2015, 2100, l)

# Aggregation function
def aggregate_data(lats, lons, models, l, years):
    years = np.round(years).astype(int)  # Ensure years are integers

    df = pd.DataFrame({
        'Latitude': lats.ravel(),
        'Longitude': lons.ravel(),
        'Model': np.repeat(models, l),
        'Year': years.repeat(len(models))
    })

    lat_bins = np.arange(-90, 90, 2)
    lon_bins = np.arange(-180, 180, 2)

    df['lat_bin'] = pd.cut(df['Latitude'], bins=lat_bins)
    df['lon_bin'] = pd.cut(df['Longitude'], bins=lon_bins)

    aggregated_data = df.groupby(['lat_bin', 'lon_bin', 'Year']).size().reset_index(name='count')

    return aggregated_data

aggregated_data = aggregate_data(lats, lons, models, l, years)

# Plot function
def plot_data_for_year(aggregated_data, year, region_extent):
    year_data = aggregated_data[(aggregated_data['Year'] == year) & (aggregated_data['count'] > 0)]

    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
    ax.set_extent(region_extent, crs=ccrs.PlateCarree())

    ax.add_feature(cfeature.LAND, facecolor='lightgrey')
    ax.add_feature(cfeature.BORDERS, edgecolor='white')

    for index, row in year_data.iterrows():
        lat_center = row['lat_bin'].mid
        lon_center = row['lon_bin'].mid
        size = row['count'] * 1000  # Adjust scaling factor as needed
        ax.scatter(lon_center, lat_center, s=size, color='red', alpha=0.5)

    plt.show()

# Define the region of interest and plot for a specific year
region_extent = [-20, 160, -35, 60]
plot_data_for_year(aggregated_data, 2020, region_extent)

    
#%%

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cfeature

# Define models and load data
models = ["ACCESS-CM2", "ACCESS-ESM1-5", "AWI-CM-1-1-MR", "CAMS-CSM1-0", "CMCC-CM2-SR5", "CMCC-ESM2",
          "CNRM-CM6-1", "CNRM-CM6-1-HR", "CNRM-ESM2-1", "EC-Earth3", "EC-Earth3-CC",
          "EC-Earth3-Veg", "EC-Earth3-Veg-LR", "GFDL-CM4", "GFDL-ESM4", "HadGEM3-GC31-LL",
          "IITM-ESM", "INM-CM4-8", "INM-CM5-0", "IPSL-CM6A-LR",
          "NorESM2-LM", "NorESM2-MM", "TaiESM1", "UKESM1-0-LL"]
m = len(models)
l = 85  # Length of the dataset for each model

# Initialize arrays for latitudes and longitudes
lats = np.zeros((m, l))
lons = np.zeros((m, l))

# Load data for each model
for i in range(m):
    lats[i] = np.load("/Applications/max_lat_lon/Data Files and Notebooks/" + models[i] + "_max_daily_lat.npy")[:85]
    lons[i] = np.load("/Applications/max_lat_lon/Data Files and Notebooks/" + models[i] + "_max_daily_lon.npy")[:85]

# Define years for each model
years = np.linspace(2015, 2100, l)

# Aggregation function
def aggregate_data_by_decade(lats, lons, models, l, years):
    df = pd.DataFrame({
        'Latitude': lats.ravel(),
        'Longitude': lons.ravel(),
        'Model': np.repeat(models, l),
        'Year': years.repeat(len(models))
    })

    # Adjusting decade bins to account for partial decades
    decades = [2015, 2020, 2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100]
    decade_labels = ['2015-2019', '2020s', '2030s', '2040s', '2050s', '2060s', '2070s', '2080s', '2090-2100']
    df['Decade'] = pd.cut(df['Year'], bins=decades, labels=decade_labels, right=False)

    lat_bins = np.arange(-90, 90, 2)
    lon_bins = np.arange(-180, 180, 2)

    df['lat_bin'] = pd.cut(df['Latitude'], bins=lat_bins)
    df['lon_bin'] = pd.cut(df['Longitude'], bins=lon_bins)

    aggregated_data = df.groupby(['lat_bin', 'lon_bin', 'Decade']).size().reset_index(name='count')

    return aggregated_data

aggregated_data = aggregate_data_by_decade(lats, lons, models, l, years)

# Define some example sizes and their labels for the legend
size_examples = [1, 10, 50]  # Choose sizes that are representative of your data
size_labels = ['1', '10', '50']  # Labels corresponding to the example sizes


def plot_decade_data(aggregated_data, unique_decades, n_rows, n_cols, size_multiplier, alpha_value, size_examples, size_labels):
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5), subplot_kw={'projection': ccrs.PlateCarree()})
    axes = axes.ravel()  # Flatten the axes array for easy indexing

    for i, decade in enumerate(unique_decades):
        ax = axes[i]
        ax.set_extent([-20, 160, -35, 60], crs=ccrs.PlateCarree())
        ax.add_feature(cfeature.LAND, facecolor='lightgrey')
        ax.add_feature(cfeature.BORDERS, edgecolor='white')

        decade_data = aggregated_data[(aggregated_data['Decade'] == decade) & (aggregated_data['count'] > 0)]
        for index, row in decade_data.iterrows():
            lat_center = row['lat_bin'].mid
            lon_center = row['lon_bin'].mid
            size = row['count'] * size_multiplier
            ax.scatter(lon_center, lat_center, s=size, color='red', alpha=alpha_value)

        ax.set_title(f"Decade: {decade}")

    # Custom legend
    legend_elements = [plt.scatter([], [], s=size * size_multiplier, color='red', label=label, alpha=alpha_value) 
                       for size, label in zip(size_examples, size_labels)]
    plt.legend(handles=legend_elements, title='Number of Records', bbox_to_anchor=(1.05, 1), loc='upper left')

    # Hide any unused subplots
    for j in range(i+1, n_rows * n_cols):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()
    
# Determine the number of rows and columns for the subplot grid
unique_decades = aggregated_data['Decade'].unique()
n_decades = len(unique_decades)
n_cols = 3  # Example: 3 columns
n_rows = n_decades // n_cols + (n_decades % n_cols > 0)


# Plot the data with the updated function
plot_decade_data(aggregated_data, unique_decades, n_rows, n_cols, 5, 0.5, size_examples, size_labels)
#%%
# Define models and load data
models = ["ACCESS-CM2", "ACCESS-ESM1-5", "AWI-CM-1-1-MR", "CAMS-CSM1-0", "CMCC-CM2-SR5", "CMCC-ESM2",
          "CNRM-CM6-1", "CNRM-CM6-1-HR", "CNRM-ESM2-1", "EC-Earth3", "EC-Earth3-CC",
          "EC-Earth3-Veg", "EC-Earth3-Veg-LR", "GFDL-CM4", "GFDL-ESM4", "HadGEM3-GC31-LL",
          "IITM-ESM", "INM-CM4-8", "INM-CM5-0", "IPSL-CM6A-LR",
          "NorESM2-LM", "NorESM2-MM", "TaiESM1", "UKESM1-0-LL"]
m = len(models)
l = 85  # Length of the dataset for each model

# Initialize arrays for latitudes and longitudes
lats = np.zeros((m, l))
lons = np.zeros((m, l))

# Load data for each model
for i in range(m):
    lats[i] = np.load("/Applications/max_lat_lon/Data Files and Notebooks/" + models[i] + "_max_daily_lat.npy")[:85]
    lons[i] = np.load("/Applications/max_lat_lon/Data Files and Notebooks/" + models[i] + "_max_daily_lon.npy")[:85]

# Define years for each model
years = np.linspace(2015, 2100, l)

# Aggregation function
def aggregate_data_by_decade(lats, lons, models, l, years):
    df = pd.DataFrame({
        'Latitude': lats.ravel(),
        'Longitude': lons.ravel(),
        'Model': np.repeat(models, l),
        'Year': years.repeat(len(models))
    })

    # Adjusting decade bins to account for partial decades
    decades = [2015, 2020, 2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100]
    decade_labels = ['2015-2019', '2020s', '2030s', '2040s', '2050s', '2060s', '2070s', '2080s', '2090-2100']
    df['Decade'] = pd.cut(df['Year'], bins=decades, labels=decade_labels, right=False)

    lat_bins = np.arange(-90, 90, 2)
    lon_bins = np.arange(-180, 180, 2)

    df['lat_bin'] = pd.cut(df['Latitude'], bins=lat_bins)
    df['lon_bin'] = pd.cut(df['Longitude'], bins=lon_bins)

    aggregated_data = df.groupby(['lat_bin', 'lon_bin', 'Decade']).size().reset_index(name='count')

    return aggregated_data


# Call the aggregation function to get aggregated_data
aggregated_data = aggregate_data_by_decade(lats, lons, models, l, years)

# Add midpoints
aggregated_data['lat_mid'] = aggregated_data['lat_bin'].apply(lambda x: x.mid).astype(float)
aggregated_data['lon_mid'] = aggregated_data['lon_bin'].apply(lambda x: x.mid).astype(float)

# Define the regions with their geographical boundaries
regions = {
    'Middle East and India': {'extent': [25, 92, 5, 35], 'title': 'Middle East, India, and parts of North Africa'},
    'Australia': {'extent': [110, 155, -40, -10], 'title': 'Australia'}
}


def plot_decades_stacked(aggregated_data, unique_decades, regions, size_multiplier, alpha_value, size_examples, size_labels):
    # Calculate the number of rows and columns for the subplot grid
    # We will have 2 plots (regions) per decade, and each pair of plots will be stacked vertically
    n_decades = len(unique_decades)
    n_regions = len(regions)
    
    # We will need twice as many rows as there are decades, because each decade has 2 regions stacked
    n_rows = n_decades * 2  # 2 rows per decade for stacking
    n_cols = 1  # All regions for a single decade will be in one column

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, n_rows * 5), subplot_kw={'projection': ccrs.PlateCarree()})
    
    # Flatten the axes for easier handling
    axes = axes.flatten()
    
    for i, decade in enumerate(unique_decades):
        for j, (region_name, region_info) in enumerate(regions.items()):
            # Calculate the index for the subplot
            ax_idx = i * n_regions + j
            ax = axes[ax_idx]
            
            ax.set_extent(region_info['extent'], crs=ccrs.PlateCarree())
            ax.add_feature(cfeature.LAND, facecolor='lightgrey')
            ax.add_feature(cfeature.BORDERS, edgecolor='white')
            ax.set_title(f"{decade} - {region_name}")

            # Filter data for the current region and decade
            decade_data = aggregated_data[(aggregated_data['Decade'] == decade) & (aggregated_data['count'] > 0)]
            filtered_data = decade_data[
                (decade_data['lat_mid'] >= region_info['extent'][2]) & (decade_data['lat_mid'] <= region_info['extent'][3]) &
                (decade_data['lon_mid'] >= region_info['extent'][0]) & (decade_data['lon_mid'] <= region_info['extent'][1])
            ]
            
            ax.scatter(filtered_data['lon_mid'], filtered_data['lat_mid'], s=filtered_data['count'] * size_multiplier, color='red', alpha=alpha_value)

    # Add a single legend for the entire figure
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    legend_elements = [plt.scatter([], [], s=size * size_multiplier, color='red', label=str(size), alpha=alpha_value) for size in size_examples]
    fig.legend(handles=legend_elements, title='Number of Records', loc='lower center', ncol=len(size_examples), bbox_to_anchor=(0.5, -0.05))

    plt.show()

# Parameters for the plot
size_examples = [1, 10, 50]  # Example sizes for the legend
size_labels = ['1', '10', '50']  # Labels for the sizes

# Call the function with your aggregated data
plot_decades_stacked(aggregated_data, sorted(aggregated_data['Decade'].unique()), regions, 5, 0.5, size_examples, size_labels)

#%%
def plot_decades_in_grid(aggregated_data, unique_decades, regions, size_multiplier, alpha_value, size_examples, size_labels):
    # Define the grid layout
    n_rows, n_cols = 3, 3  # Three rows and three columns

    for region_name, region_info in regions.items():
        # Create a new figure for each region
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 15), subplot_kw={'projection': ccrs.PlateCarree()})
        axes = axes.flatten()  # Flatten the axes array for easy iteration
        
        # Plot each decade in its own subplot
        for i, decade in enumerate(unique_decades):
            if i < n_rows * n_cols:
                ax = axes[i]
            else:
                # If there are more than 9 decades, start a new figure
                plt.tight_layout()
                plt.show()
                fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 15), subplot_kw={'projection': ccrs.PlateCarree()})
                axes = axes.flatten()
                ax = axes[0]  # Reset to the first subplot of the new figure

            ax.set_extent(region_info['extent'], crs=ccrs.PlateCarree())
            ax.add_feature(cfeature.LAND, facecolor='lightgrey')
            ax.add_feature(cfeature.BORDERS, edgecolor='white')
            ax.set_title(f"{decade} - {region_name}")

            # Filter data for the current region and decade
            decade_data = aggregated_data[(aggregated_data['Decade'] == decade) & (aggregated_data['count'] > 0)]
            filtered_data = decade_data[
                (decade_data['lat_mid'] >= region_info['extent'][2]) & (decade_data['lat_mid'] <= region_info['extent'][3]) &
                (decade_data['lon_mid'] >= region_info['extent'][0]) & (decade_data['lon_mid'] <= region_info['extent'][1])
            ]

            ax.scatter(filtered_data['lon_mid'], filtered_data['lat_mid'], s=filtered_data['count'] * size_multiplier, color='red', alpha=alpha_value)

        # Hide any unused subplots
        for j in range(i+1, n_rows * n_cols):
            fig.delaxes(axes[j])

        # Add a single legend for the entire figure
        plt.tight_layout()
        legend_elements = [plt.scatter([], [], s=size * size_multiplier, color='red', label=str(size), alpha=alpha_value) for size in size_examples]
        fig.legend(handles=legend_elements, title='Number of Records', loc='lower center', ncol=len(size_examples), bbox_to_anchor=(0.5, -0.05))

        plt.show()

# Example sizes for the legend
size_examples = [1, 10, 50]
size_labels = ['1', '10', '50']

# Call the function with your aggregated data
plot_decades_in_grid(aggregated_data, sorted(aggregated_data['Decade'].unique()), regions, 5, 0.5, size_examples, size_labels)

#%%

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cfeature

models = [
    "ACCESS-CM2", "ACCESS-ESM1-5", "AWI-CM-1-1-MR", "CAMS-CSM1-0", "CMCC-CM2-SR5", "CMCC-ESM2",
    "CNRM-CM6-1", "CNRM-CM6-1-HR", "CNRM-ESM2-1", "EC-Earth3", "EC-Earth3-CC",
    "EC-Earth3-Veg", "EC-Earth3-Veg-LR", "GFDL-CM4", "GFDL-ESM4", "HadGEM3-GC31-LL",
    "IITM-ESM", "INM-CM4-8", "INM-CM5-0", "IPSL-CM6A-LR",
    "NorESM2-LM", "NorESM2-MM", "TaiESM1", "UKESM1-0-LL"
]

m = len(models)
l = 85  # max time steps you want

lats = np.zeros((m, l))
lons = np.zeros((m, l))

for i in range(m):
    lats[i] = np.load(f"/Applications/max_lat_lon/Data Files and Notebooks/{models[i]}_max_daily_lat.npy")[:85]
    lons[i] = np.load(f"/Applications/max_lat_lon/Data Files and Notebooks/{models[i]}_max_daily_lon.npy")[:85]


# --- Aggregation ---
def aggregate_data_by_yearbin(lats, lons, models, l, years):
    df = pd.DataFrame({
        'Latitude': lats.ravel(),
        'Longitude': lons.ravel(),
        'Model': np.repeat(models, l),
        'Year': np.tile(years, m)
    })

    bins = [2015, 2020, 2030, 2040, 2050, 2060, 2070, 2080, 2090, 2101]
    labels = ['2015', '2020', '2030', '2040', '2050', '2060', '2070', '2080', '2090']
    df['YearBin'] = pd.cut(df['Year'], bins=bins, labels=labels, right=False)

    df['lat_bin'] = pd.cut(df['Latitude'], bins=np.arange(-90, 90, 2))
    df['lon_bin'] = pd.cut(df['Longitude'], bins=np.arange(-180, 180, 2))

    return df.groupby(['lat_bin', 'lon_bin', 'YearBin']).size().reset_index(name='count')

# --- Plotting ---
def plot_yearly_bins(aggregated_data, unique_bins, n_rows, n_cols, size_multiplier=5, alpha_value=0.5, size_examples=[1, 10, 50], size_labels=['1', '10', '50']):
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5), subplot_kw={'projection': ccrs.PlateCarree()})
    axes = axes.ravel()

    for i, year_bin in enumerate(unique_bins):
        ax = axes[i]
        ax.set_extent([-20, 160, -35, 60], crs=ccrs.PlateCarree())
        ax.add_feature(cfeature.LAND, facecolor='lightgrey')
        ax.add_feature(cfeature.BORDERS, edgecolor='white')

        bin_data = aggregated_data[(aggregated_data['YearBin'] == year_bin) & (aggregated_data['count'] > 0)]
        for _, row in bin_data.iterrows():
            lat = row['lat_bin'].mid
            lon = row['lon_bin'].mid
            ax.scatter(lon, lat, s=row['count'] * size_multiplier, color='red', alpha=alpha_value)

        ax.set_title(str(year_bin), fontsize=14)

    legend = [plt.scatter([], [], s=s * size_multiplier, color='red', alpha=alpha_value, label=lbl)
              for s, lbl in zip(size_examples, size_labels)]
    plt.legend(handles=legend, title='Record Count', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12, title_fontsize=13)

    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()

# --- Run everything ---
aggregated_data = aggregate_data_by_yearbin(lats, lons, models, l, years)
unique_bins = aggregated_data['YearBin'].cat.categories
n_cols = 3
n_rows = int(np.ceil(len(unique_bins) / n_cols))

plot_yearly_bins(aggregated_data, unique_bins, n_rows, n_cols)



# In[15]:


for i in range(m):
    #plt.subplot(6, 4, i + 1)
    plt.scatter(year, lats[i], s = 1., c = year, cmap = plt.cm.coolwarm)
    
    #plt.ylim(-40., 40.)
    #plt.xlim([2016., 2101.])
    #plt.colorbar()
    plt.title("Latitudes vs. Year of all models")


# In[16]:


model = 15
plt.scatter(year, lats[model], s = 1., c = year, cmap = plt.cm.coolwarm)
plt.title("Latitudes vs. Year (" + models[model] + ")")


# In[17]:


import matplotlib as mtplt
model = 15
mtplt.pyplot.plot(year, lats[model])
mtplt.pyplot.title("Latitudes vs. Year (" + models[model] + ")")


# In[66]:


width = 0.25  # the width of the bars


# In[138]:


for i in range(m):
    plt.subplot(6, 4, i + 1)
    #mtplt.pyplot.plot(year, lats[i])
    plt.scatter(year, lats[i], s = 8., c = year, cmap = 'YlOrRd')
    plt.ylim(-40., 40.)
    plt.xlim([2016., 2101.])
    plt.tight_layout()
    #plt.title(m + 1, models)
    
    #plt.title("Latitudes vs. Year for all models (scatter)", fontdict=None, loc='right',)


# In[19]:


for i in range(m):
    plt.subplot(6, 4, i + 1)
    mtplt.pyplot.plot(year, lats[i])
    #plt.scatter(year, lats[i], s = 2., c = year, cmap = plt.cm.coolwarm)

    
    plt.ylim(-40., 40.)
    plt.xlim([2016., 2101.])
    #plt.title("Latitude vs. Year for all models (line)", fontdict=None, loc='right',)


# In[20]:


for i in range(2,3):
    plt.plot(lons[i], lats[i], 'o')

